%
% 計測自動制御学会システム・インテグレーション部門学術講演会2012原稿サンプルファイル
%                                           October 4, 2012
% Based on 計測自動制御学会システム・情報部門学術講演会2012原稿サンプルファイル
%                                           April 28, 2012
% Based on 第7回計測自動制御学会制御部門大会原稿サンプルファイル
%                                           October 18, 2007
% Based on 第5回計測自動制御学会制御部門大会原稿サンプルファイル
%            近野敦 konno@space.mech.tohoku.ac.jp    March 05, 2005
%

\documentclass[10pt,a4paper]{jarticle}
\usepackage{tc2016_utf}
\usepackage[dvipdfmx]{graphicx,color}
\usepackage[fleqn]{amsmath}
\usepackage{algorithm,algorithmic}
\usepackage{amssymb,epsfig}
\usepackage{ascmac}

\usepackage{url}
\usepackage{bm}
\usepackage{ascmac}
\usepackage{pifont}
%\usepackage{multirow}
\usepackage{enumerate}
%\usepackage{cases}
\usepackage{type1cm}
\usepackage{here}

\def\vec#1{\mbox{\boldmath$#1$}}
\def\vector#1{\mbox{\boldmath $#1$}}

\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\newcommand{\argmin}{\mathop{\rm arg~min}\limits}
\newcommand{\umax}{\mathop{\rm max}\limits}

\def\R{{\Bbb R}}
\def\Z{{\Bbb Z}}

\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\dbltopfraction}{0.8}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.8}
\renewcommand{\dblfloatpagefraction}{0.8}
\setcounter{topnumber}{3}
\setcounter{bottomnumber}{3}
\setcounter{totalnumber}{3}

\begin{document}
\title{\fontsize{16pt}{0pt}\selectfont 九州工業大学CIR-KITのつくばチャレンジへの取り組み}
\author{\fontsize{12pt}{0pt} 有田 裕太（九州工業大学）~ 田中 良道（九州工業大学） \\ ~ 森田 賢（九州工業大学）~西田 健（九州工業大学）}
\engtitle{
   \fontsize{16pt}{40pt}\selectfont 
}
\engauthor{
  \fontsize{12pt}{0pt}\selectfont Arita Yuta(Kyutech), Tanaka Ryodo(Kyutech), \\ Morita Masaru(Kyutech) and Nishida Takeshi(Kyutech)
}

\abstract{
\fontsize{9pt}{0pt}\selectfont
}

\maketitle\thispagestyle{empty}
\pagestyle{empty}

\section{はじめに}
\label{sec:intro}
我々は，九州工業大学工学部の学部生を中心としたロボット開発チームであり，屋内外の移動を行う福祉ロボットの開発に取り組んでいる．このような福祉ロボットに必要とされる機能には，案内・荷物の運搬・搭乗者の安全な搬送・周囲環境に対する回避，発見，追従動作などが挙げられる．そこで我々は市販の電動カートを改造し，これらの作業を行うための福祉ロボット(KIT-C3)を開発した．本稿では，このロボットの開発とつくばチャレンジ2016での実験結果について報告する．

\section{ロボットの構成}
\subsection{KIT-C3}
\subsubsection{ハードウェア構成}
本ロボットでは，シニアカータウンカート(スズキ株式会社製TC1A4)の走行系を用いた．シニアカーの走行系は，バッテリーや走行安定性，防水性など，様々な面で屋外での走行機能の信頼性が高く，故障などの問題の発生率が低い．さらに，ホイールレングスが1[m]程度あるため，直進走行性能が高く，自動走行制御に対して再現性が高いというアドバンテージがある．一方で，つくばチャレンジの他チームの小型走行ロボットよりは比較的車体が大きく，車重も97[kg]と重い．Fig.\ref{213021_18Dec14}にKIT-C3の外観を示す．また，Fig.はシニアカーの座席した部分の写真であり，自律走行をさせるにあたって必要なマイコンや電源装置が収められている．Fig.はステアリングを操作するためのモータを設置した箇所である．自律走行時には3Dプリンタで作成したカバーを取り付けている．

\begin{figure}
  \centering
  \includegraphics[width=7cm]{fig/eps/kitc3.eps}
  \caption{KIT-C3の外観}
  \label{213021_18Dec14}
\end{figure}

\subsubsection{センサ構成}
KIT-C3は環境観測用センサとして前方にLRF(北陽電機製UTM-30LX)を2台，後方にも同様のLRFを1台搭載している．また，ロボットの状態観測用センサとしてロータリーエンコーダ(MUTOH製UM-125)をステアリング軸に1つ取り付けている．このセニアカーの後輪は独立に2つのモータとエンコーダが搭載されており，そのエンコーダ情報をiXis Research社製マイコンボード iMCs01 により取得している．

\subsubsection{全体の構成}
ロボットへの速度指令やロータリーエンコーダの処理用マイコンとして iXs Research 社のiMCs01を用いた．シニアカーの速度制御はiMCs01で0-5[V]の電圧を生成しシニアカーのアクセル信号部に印加することで実現している．またステアリング操舵のためステッピングモータの制御にArduino Unoを用いた．制御用PCはラップトップPCを用いており，OSはUbuntu 14.04を使用した．以上の構成の概要をFig.\ref{225251_18Dec14}に示す．ラップトップPCとiMCs01やURGとはUSB接続である．また，Fig.\ref{213021_18Dec14}における破線はシニアカーの制御基板によって制御されていることを表す．

\begin{figure}[tbp]
  \centering
  \includegraphics[width=6cm]{fig/eps/kitc3_overview.eps}
  \caption{KIT-C3のシステムの概要}
  \label{225251_18Dec14}
\end{figure}

\section{ソフトウェアの構成}
\subsection{ROS}
開発したロボットには先述のとおりROSを導入している．これはソフトウェアの再利用性を意識したものである．実際，KIT-C3で開発したソフトウェアをKIT-C4やKIT-C5で再利用することが可能であり，開発時間の短縮を図ることができる．また，ROSを用いることでデバッグや可視化に有効なツールだけでなく，世界中の開発者が作成したライブラリを容易に利用することができる．ゆえに我々は，ソフトウェア構成においてROSを採用した．
\subsection{走行手法}
走行手法には，ROSのnavigationスタックを利用した．予め環境地図を作成し，環境地図上にWaypointを1メートル毎に設定し，それらを順に辿っていくようにして自律移動を行った．Waypointの設定はROSの可視化ソフトウェアrviz上でクリックやドラッグ操作で設定できるパッケージを開発しこれを用いた．経路生成および障害物回避にはmove\_baseパッケージを用いた．また，自己位置推定にはAMCL（AdaptiveMontecalro Localization)を用いた．今年も昨年と同様に前方と後方に取り付けた2台のLRFで自己位置推定を行った．また，グローバルパスプランニングにはcarrot\_planerを用いた。これはデフォルトのNavfnのグローバルプランナーでは人物発見の際に問題が生じたためである。また、ローカルプランナーにはDWAローカルプランナーを利用した。いずれも、ROSではmove\_baseのプラグインとして提供されているため簡単に利用することが出来る。
本番では人物探索を行うことが出来なかったが，人物探索についても準備を行った．予め設定したwaypointに探索エリアに関する情報を保持しておき，waypointの切替時に探索エリアかつ探索対象を発見して場合に探索対象候補へのアプローチを行った．探索対象の検出方法については後述する．

\subsection{環境地図}
環境地図はROSのパッケージ化されたgmappingを用いて作成した．昨年は前後のLRFを2台のデータを利用して地図作成を行ったが，つくばに到着後に取り付けたLRFの位置がずれていたことに気付かず，そのままデータを取ってしまったため，前方のLRFのみを利用して地図作成を行った．環境地図は5[cm]四方の占有格子地図とした．また，確認走行を完了したあとは大清水公園と公園の外でそれぞれ地図を作成し画像編集ソフトを用いて1つに統合したものを用いた．作成した地図はここでは示さないが，遠隔監視システムの項にて示す．


% \begin{figure*}
%   \centering
%   \includegraphics[width=14cm]{fig/png/gridmap.png}
%   \caption{KIT-C3の作成した環境地図(コース全域)}
%   \label{204704_18Dec14}
% \end{figure*}

\section{探索対象の発見}
課題コース途中で探索エリアにおいて特定人物（探索対象）の発見という課題も設定されている．我々はこの課題を3次元LIDARから得られた3次元点群の処理による実現を試みた．

\subsection{地面点群の除去}
3次元LIDAR(Hokuyo YVT-X002)で得られた3次元点群からまず地面点群の除去を行う．LIDARの取り付け位置は既知であり，つくばチャレンジ2016の課題コースでは探索エリアは平面だったため，地面点群はZ方向の高さによって消去した．
\subsection{クラスタリング}
地面点群が除去された点群をユークリディアンクラスタリングによりクラスタリングを行った．ユークリディアンクラスタリングではある点群からのユークリッド距離がしきい値以下の場合に同一クラスタとする手法である．
\subsection{識別}
クラスタリング後の点群の識別には夏迫らがつくばチャレンジ2015のレポートで提案されていた手法を参考にSVMによる手法を利用した．しかし，特徴量に関しては異なる特徴量を用いた．
\subsubsection{点群特徴量}
識別に利用した特徴量$f_{i}$は6次元からなる$f_{i1}$と7次元からなる$f_{i2}$の2つの特徴ベクトルを並べた13次元の特徴量である．
まず，$f_{i1}$は点群の3次元共分散行列の要素であり次式で示される．
\begin{eqnarray}
 \Sigma = \frac{1}{n-1}\sum_{\vec{x_{k}}(i)\in C_{i}}\vec{x}_{k}^{(i)}\vec{x}_{k}^{(i)T}\label{234310_5Dec16}
\end{eqnarray}
ここで，$\vec{x}_{k}^{(i)}\triangleq[x_{k}^{(i)} y_{k}^{(i)} z_{k}^{(i)}]^{T}$はクラスタ内に含まれる点群のクラスタ重心を原点とする座標である．この行列は対称行列であるため，行列要素のうち重複を除いた6要素を特徴量として，$\vec{f}_{i1} = [f_{i11}, \cdots, f_{i16}]^{T}$とする．
式\eqref{234310_5Dec16}に示す3次元共分散行列の固有値を$\lambda_{1}, \lambda_{2}, \lambda_{3}$とする．ただし，$\lambda_{1} < \lambda_{2} < \lambda_{3}$である．この固有値を元にTable.\ref{222525_5Dec16}に示す特徴量を計算しこれを$\vec{f}_{i2}$とした．
\begin{table}
 \centering
 \caption{3D features of points}
 \label{222525_5Dec16}
 \begin{tabular}{|c|c|c|}
  \hline
  $f_{i21}$ & Linearity & $(\lambda_{1}-\lambda_{2})/\lambda_{1}$ \\
  $f_{i22}$ & Planarity & $(\lambda_{2}-\lambda_{3})/\lambda_{1}$ \\
  $f_{i23}$ & Scattering & $\lambda_{3}/\lambda_{1}$ \\
  $f_{i24}$ & Omnivariance & $\sqrt[3]{\lambda_{1}\lambda_{2}\lambda_{3}}$ \\
  $f_{i25}$ & Anisotropy & $(\lambda_{1}-\lambda_{3})/\lambda_{1}$ \\
  $f_{i26}$ & Eigenetropy & $-\sum^{3}_{i=1}\lambda_{i}\ln\lambda_{i}$ \\
  $f_{i27}$ & Change of curvature & $\lambda_{3}/(\lambda_{1}+\lambda_{2}+\lambda_{3})$ \\
  \hline
 \end{tabular}
\end{table}

\subsubsection{SVM}
得られた特徴量をSVM(Support Vector Machine)を用いて識別する．実装にはLIBSVMを利用した．学習はクラスタリングによって得られた点群を287個用意して，それらを探索対象とその他の2値分類問題として行った．学習の結果訓練データで99.3\%、テストデータでも85\%の精度が得られた．

\subsection{探索対象へのアプローチ}
実用上は学習データ数が少なかったこともあり，誤検出が多くなってしまった．そこで，検出位置から1メートル以内で複数回，探索対象と認識した場合にのみアプローチすることにした．
探索対象が見つかった場合には，Fig.\ref{142629_6Dec16}のように探索対象を中心とする円とロボットの自己位置と探索対象を直線結んだ時の交点座標のうち，ロボットに近い方の交点を新たなゴールとして設定する．

\begin{figure}[ht]
 \centering
 \includegraphics[width=5cm]{./fig/eps/approach_to_target.eps}
 \caption{探索対象へのアプローチ}
 \label{142629_6Dec16}
\end{figure}

以下にこれまでに述べた手法をまとめる．
\begin{enumerate}
 \item 3DLIDARによって得られた点群から地面点群を除去する
 \item 地面点群が除去された点群をクラスタリングする
 \item クラスタリング結果をSVMによって識別し，探索対象ならアプローチ候補とする
 \item アプローチ候補のうち，1m以内で複数回アプローチ候補が検出された場合にアプローチ対象とする
\end{enumerate}

\subsubsection{人物探索のつくばチャレンジにおける実験結果}
これまでに説明した手法は九州工業大学戸畑キャンパス内に設定したコース内では上手く機能していた．しかし，試験走行日にこれらを実際に試してみたところ，学内で実験した場合よりも多く誤認識してしまい，それら全てにアプローチを試みるという結果になってしまった．そのため，制限時間内で課題コースを完走することが難しいと判断し，本走行では人物探索機能を起動させなかった．
課題コースでは建物の角などを探索対象として多く誤認識してしまっていた．学内で得られたサンプルには建物の角など人工物があまり含まれておらず，結果としてそれらを上手く識別できていなかったと考えられる．すなわち，学習に用いたデータが少なすぎたことが問題だと考えられる．

\subsection{遠隔監視システム}
つくばチャレンジの注意事項等について，「ロボットの位置や状況のステーションにおけるモニタリング」を強く推奨すると明記されている．我々は本要求事項を達成する遠隔監視システムを構築したので，その機能とネットワーク環境について述べる．
ただし，本システムは大会当日に機能させることが出来なかったため，以下では開発時の情報を用いて説明する．

初めに，遠隔監視について述べる．監視画面として，ロボットの現在姿勢を地図上に表示させる形式を採用した．現在姿勢，あるいは現在姿勢と経路履歴の両方，を選択的に表示できるようにした．現在姿勢を表示した様子をFig.\ref{monitor}に示す．なお，同図で画像の一部のみを拡大をしている箇所は説明のために加工を施したもので，実際のシステムでは背景の大域地図上にロボットの姿勢が表示されるのみである．
\begin{figure}
    \centering
    \includegraphics[width=6cm]{fig/png/monitor.png}
    \caption{遠隔監視システムで地図上に現在姿勢を表示させた様子．}
    \label{monitor}
\end{figure}

次に，通信環境について述べる．監視端末とロボット間の通信回線として商用モバイル回線を利用し，VPNで接続を行った．VPNシステムとして，OpenVPNを採用した．遠隔監視PCをサーバ，ロボットをクライアントとしてVPNネットワークを構成し，ROS ネットワークと連携させることで，遠隔監視を実現した．

ここで，工夫点について記述する．本システム開発当初，本構成でROSの可視化ツールであるrvizによる監視を試みたところ，rvizはリアルタイムに更新される位置情報を全て取得しようと試みるのだが，商用回線の通信速度ではその情報量に対応しきれず，情報の更新漏れが頻繁に発生してしまった．また，パケット通信容量が膨大で，契約した通信回線の上限を容易に超えてしまう恐れがあり，遠隔監視そのものが実現できなくなる懸念があった．
そこで，ロボットが一定距離を移動する毎に，自身の位置を監視端末に送信する仕様に変更することで，更新漏れとパケット通信料の問題を解決した．検証段階では送信間隔5[m]毎に設定したが，ロボットの位置を追跡するには十分な周期であった．

最後に，本機能の展望を記述する．ネットワークシステムを独自で構築したため，位置に限らず任意の情報を遠隔監視するための基盤技術を確立できた．期待される機能の例として，ロボットの現在速度，電池残量，検出した人物の画像等といった，遠隔監視に有益な情報表示機能が挙げられる．

\section{結果と考察}
\subsection{実験走行}
LRFを2台用いることによって環境地図が安定して作成できるようになったため，一度手動で操作してデータ取りを行った後，すぐに地図作成を完了することができた．また，実験走行では横断歩道手前まで何度か走行できたものの，横断歩道を通過する実験を行うことが出来なかった．横断歩道へ侵入する際の段差が想定よりも大きく，車体が前のめりに傾いた際に地面を障害物として認識してしまっていた．他にも，コース後半の橋を渡ったあとの下り坂でも同様の現象が発生したことがあった．

\subsection{本走行結果}
本走行では雨だったものの，ラップトップPCをビニール袋で覆う以外には特に防水処理は行っていない．LRFが雨を障害物として認識することがあり，頻繁に一時停止するものの，順調に走行し，横断歩道手前までの約1420[m]自律走行を行った．しかし，横断歩道手前で一時停止出来なかったため，オペレータが緊急停止スイッチを押し，停止させた．
横断歩道手前のwaypointに到達したら一時停止するような処理を実装していたが，waypointの位置の設定ミスが原因だった．横断歩道手前での実験が不十分だったことが設定ミスの原因である．

昨年からハードウェア構成やソフトウェア構成をほとんど変更していないものの，地図作成や自己位置推定に用いたLRFを1台から2台に変更し，360度から情報を得ることができるようになったことで格段に安定性を大きくすることが出来た．また，オドメトリの精度向上も自己位置推定の安定性向上につながった．しかしながら，広い場所では自己位置推定が安定しない場合があったため，3DLIDARなどを利用した自己位置推定を利用して解決を図りたい．

また，今回は完走を目標としたため人物発見には取組めていない．次回の参加では人物発見を行い，課題の完全達成を目指したい．


\section{開発状況などに関して}
本年度の開発では，昨年度までに開発してきたロボットを用いたが，本年度の開発期間は大会本走行の約1ヶ月前からであった．更に，開発を行った人数は3名で，開発期間の約半分は2名がKIT-C3に，1名がKIT-C4の開発を行っていた．さらに開発メンバーの一人は，遠隔地におり，実際にロボットが間近にある環境で開発を行う回数は，ほんの数回であった．このような短期間かつ少人数で開発を行う際に，ソフトウェアの仕様統一が行い易いROSの影響は非常に大きかったと言える．また，開発を行う際に，オンラインでソースコードを共有できるGitHubの利用も非常に効果的であった．
開発を行うにあたり，我々のチームは実験走行になかなか参加出来ないため，学内での実験を積み重ねてきた．学内の実験においても約1000[m]程度の自律走行が安定してできていた．しかし，学内での実験では他のロボットや未知の障害物などが少なく，道幅は広く，起伏が殆ど無い環境だったためつくばチャレンジの環境では上手く行かないことがあった．本番前の実験走行ではこの辺りの調整が大変であった．

\section{つくばでの実験の流れ}
\begin{description}
 \item[11月○○日]\mbox{}\\
	    ロボットやテントなどを梱包
 \item[11月○○日]\mbox{}\\
	    ロボットや機材などを搬送業者に引き渡し
 \item[11月○○日]\mbox{}\\
	    つくば市着　ロボットの準備
 \item[11月○○日]\mbox{}\\
	    第○回実験走行　ロボットの安全確認、大清水公園のデータ取得、大清水公園の地図作成、ウェイポイントの設定，大清水公園の自律走行，確認走行，課題コース全体のデータ取得を行った
 \item[11月○○日]\mbox{}\\
	    第○回実験走行　課題コース全体のテスト走行、探索対象の発見及びアプローチの実験，遠隔監視システムの動作確認
 \item[11月○○日]\mbox{}\\
	    本走行　朝の走行実験で第○回実験走行で上手く自律走行出来なかった箇所の地図を再度取得。ウェイポイントの再設定。交流会終了後、ロボット等の梱包
 \item[11月○○日]\mbox{}\\
	    北九州着
\end{description}
つくばチャレンジに遠方から参加する場合，なかなか実験走行に参加できないため，実験走行日にどれだけ実験できるかどうかが重要になってくる。

\section{最後に}
我々が開発したソースコードは，GitHub上で公開している．開発を行うにあたって参考にしていただければありがたい．
\url{http://github.com/Nishida-Lab/TC2015}

\section*{謝辞}
つくばチャレンジ実行委員会やつくば市の方々にはつくばチャレンジのような貴重な実験の機会を与えていただき感謝いたします．



% \begin{thebibliography}{9}% 文献が10以上のとき99，10未満のとき9
 
% \end{thebibliography}

%\appendix
%\section{}


\end{document}
